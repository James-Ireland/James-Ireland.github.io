---
layout: default
---

## Datasets
### Synthetic Operating Room Table (SORT) Dataset
<img align="right" width="480" height="240" src="./docs/assets/sORt_sampleAnnotation_org_img.png">
The Synthetic Operating Room Table (SORT) dataset is a largescale computer vision focused on instance counting, segmentation and localisation surgical instrument depictions placed on a table. 
  The depictions contained are rendered using the Unreal game engine and annotated leveraging the UnrealCV plugin (Qui, 2017). 
  SORT contains one container class, one material class (gauze) and six instrument classes namely, forceps, scalpels, pincettes (tweezers), syringes, periotomes, and scissors. 
  Each class contains two different 3D representations equally likely to be present for a given instance, with exception of the container class that leverages three different 3D models. 
  In total, we generated 89,838 images, split into 60% training (53,906), 20% validation (17,965), and 20% test (17,967), containing 365,469, 121,951 and 122,142 separate object instances, respectively. 
  The aim is to be able to count surgical instruments and materials via computer vision to aid medical staff in ensuring no instrument is retained by a patient, leading to complications such as chronic pain and sepsis. 
  Currently this is done manually, with the World Health Organisation (WHO) proposing that manual counts should be completed by two members of staff (Biswas, 2012), typically counting instruments laid out on a surface, either before or after their use. 
  This standard practice of logging the type and number of a given instrument or material to be used during an operation is not managerial overhead but crucial for the prevention of retained instruments, consumables, or materials during surgery, as these would negatively impact on a patient's recovery time or even lead to the patient's death. 
 
 
 ![SORT image](./docs/assets/sORt_sampleAnnotation_org_img.png)
 ![SORT annotations](./docs/assets/sORt_sampleAnnotation_BB_segMask_lbls.png) 
 
 ![SORT image](./docs/assets/sORt_sampleAnnotation_org_img.png "title"=%50x)
 
 
 
 
 
 
<a href="https://james-ireland.github.io/Datasets">Link</a>

## Publications

## Research interests  
* Computer Vision 
* Machine Learning 
* Artifical Inteligence  
* Robotics
* Human Robot Interaction (HRI) 
* Human Computer Interaction (HCI) 

## Contact Information
Email: James.Ireland@canberra.edu.au
